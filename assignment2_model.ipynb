{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5a203946-6741-47a0-9770-4c4cf3d65cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "712e2d07-3137-45e3-9b16-ba16e95c2704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/kelly/Downloads/redditSubmissions_cleaned-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c1258789-772c-4f1d-be4b-6d229376cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_weekend'] = df['dayofweek'].isin([5, 6]).astype(int)\n",
    "def time_period(h):\n",
    "    if 6 <= h < 12:\n",
    "        return 0\n",
    "    elif 12 <= h < 17:\n",
    "        return 1\n",
    "    elif 17 <= h < 24:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "df['time_period'] = df['hour'].apply(time_period)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32196e8b-8d55-4802-89a7-194ad88e65cb",
   "metadata": {},
   "source": [
    "features + linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4fa4086e-83da-48b5-b75a-7ff826337156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(df, mode=\"none\"):\n",
    "    text_col = 'title'\n",
    "    cat_cols = ['subreddit', 'time_period']\n",
    "    binary_cols = ['has_question', 'has_exclamation', 'is_weekend']\n",
    "    numeric_cols = ['hour', 'dayofweek', 'title_len']\n",
    "    label_col = 'popular'\n",
    "\n",
    "    if mode == \"count\":\n",
    "        vectorizer = CountVectorizer(max_features=1000, ngram_range=(1,2), stop_words='english')\n",
    "        X_counts = vectorizer.fit_transform(df[text_col].fillna(''))\n",
    "        do_log1p = True\n",
    "        if do_log1p:\n",
    "\n",
    "            X_counts = X_counts.tocoo()\n",
    "            X_counts.data = np.log1p(X_counts.data)\n",
    "            X_counts = X_counts.tocsr()\n",
    "        X_text=X_counts\n",
    "    elif mode == \"bert\":\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "        bert_model.eval()\n",
    "\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        bert_model.to(device)\n",
    "\n",
    "        titles = df[text_col].fillna(\"\").tolist()\n",
    "        batch_size = 32\n",
    "        all_features = []\n",
    "\n",
    "        for i in range(0, len(titles), batch_size):\n",
    "\n",
    "            batch = titles[i:i+batch_size]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                encoded = tokenizer(\n",
    "                    batch, return_tensors='pt',\n",
    "                    padding=True, truncation=True, max_length=32\n",
    "                )\n",
    "                ids = encoded['input_ids'].to(device)\n",
    "                att = encoded['attention_mask'].to(device)\n",
    "\n",
    "                outputs = bert_model(input_ids=ids, attention_mask=att)\n",
    "                pooled = outputs.pooler_output.cpu().numpy()\n",
    "                all_features.append(pooled)\n",
    "\n",
    "        X_text = sparse.csr_matrix(np.vstack(all_features))\n",
    "\n",
    "    elif mode == \"none\":\n",
    "        X_text = None\n",
    "\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=True)\n",
    "\n",
    "    X_cat = ohe.fit_transform(df[cat_cols])\n",
    "    X_binary = df[binary_cols].astype(float).values\n",
    "    scaler = StandardScaler()\n",
    "    X_numeric = scaler.fit_transform(df[numeric_cols].astype(float))\n",
    "    X_binary_sp = sparse.csr_matrix(X_binary)\n",
    "    X_numeric_sp = sparse.csr_matrix(X_numeric)\n",
    "    \n",
    "\n",
    "    if X_text is None:\n",
    "        X_all = sparse.hstack([ X_cat, X_binary_sp, X_numeric_sp], format='csr')\n",
    "    else:\n",
    "        X_all = sparse.hstack([X_text, X_cat, X_binary_sp, X_numeric_sp], format='csr')\n",
    "\n",
    "    y = df[label_col].values.astype(int)\n",
    "    return X_all, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "252887ed-bb30-4ffd-8944-20f2128dd63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, y = build_dataset(df, mode=\"none\")\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_all, y, test_size=0.2, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3114b0cf-dbb0-4b22-ab84-d66d6bb329d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, solver=&#x27;saga&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000, solver='saga')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    solver='saga'\n",
    ")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "58407e15-e553-4a6a-800d-4d744a98dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold(y_true, y_proba, thresholds=np.linspace(0.1,0.9,17)):\n",
    "    best_t, best_f1 = 0.5, -1\n",
    "    for t in thresholds:\n",
    "        preds = (y_proba >= t).astype(int)\n",
    "        f1 = f1_score(y_true, preds)\n",
    "        acc = accuracy_score(y_true, preds)\n",
    "        print(f\"thr={t:.2f} -> Acc={acc:.4f}, F1={f1:.4f}\")\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    return best_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2e2b81-4411-45f6-9b1d-159f4dec4757",
   "metadata": {},
   "source": [
    "bert + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789edfd2-db10-4414-b8ff-6b91d5e7088b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fb28db8-e416-4ed7-bfe4-a73b385ae776",
   "metadata": {},
   "source": [
    "This part is to encode all the features I need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b7733-567e-46ee-9dec-c92189dbf1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, cat_cols, binary_cols, numeric_cols, label_col, text_column='title', max_len=128):\n",
    "        self.df = df.copy()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cat_cols = cat_cols\n",
    "        self.binary_cols = binary_cols\n",
    "        self.numeric_cols = numeric_cols\n",
    "        self.label_col = label_col\n",
    "        self.text_column = text_column\n",
    "        self.max_len = max_len\n",
    "        for c in self.cat_cols:\n",
    "            self.df[c] = self.df[c].astype('category').cat.codes\n",
    "        for c in self.binary_cols + self.numeric_cols:\n",
    "            self.df[c] = self.df[c].astype(float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        encoded = self.tokenizer(\n",
    "            row[self.text_column],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoded['input_ids'].squeeze(0)\n",
    "        attention_mask = encoded['attention_mask'].squeeze(0)\n",
    "        cat_feats = torch.tensor(row[self.cat_cols].values.astype(int), dtype=torch.long)\n",
    "        numeric_feats = torch.tensor(row[self.numeric_cols + self.binary_cols].values.astype(float), dtype=torch.float)\n",
    "        label = torch.tensor(row[self.label_col], dtype=torch.float)\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'cat_feats': cat_feats,\n",
    "            'numeric_feats': numeric_feats,\n",
    "            'label': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e0e50f-6b5c-49d8-a9d6-5e85d995d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "text_column = 'title'\n",
    "max_len = 32\n",
    "batch_size = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3afb150-f95a-4b17-aa3d-040da8e67ed2",
   "metadata": {},
   "source": [
    "This part is to build, split and transform dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155411c0-2bf6-4061-82b6-e337c30837d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = MyDataset(df, tokenizer, cat_cols, binary_cols, numeric_cols, label_col, text_column, max_len)\n",
    "indices = np.arange(len(full_dataset))\n",
    "train_idx, temp_idx = train_test_split(indices, test_size=0.2, random_state=42, stratify=df[label_col])\n",
    "val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42, stratify=df.iloc[temp_idx][label_col])\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "val_dataset = Subset(full_dataset, val_idx)\n",
    "test_dataset = Subset(full_dataset, test_idx)\n",
    "y_train = df.iloc[train_idx][label_col].values\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e42e78-db9d-4eb8-bd7e-6f00624cf244",
   "metadata": {},
   "source": [
    "Put my features in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df461375-e861-43f7-af19-6595104ebde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedditModel(nn.Module):\n",
    "    def __init__(self, num_categories, cat_cols, numeric_cols, binary_cols):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(num_categories[c], min(50, num_categories[c]))\n",
    "            for c in cat_cols\n",
    "        ])\n",
    "        cat_dim = sum([min(50, num_categories[c]) for c in cat_cols])\n",
    "        numeric_dim = len(numeric_cols) + len(binary_cols)\n",
    "        input_dim = 768 + cat_dim + numeric_dim\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, input_ids, attention_mask, cat_feats, numeric_feats):\n",
    "        bert_out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = bert_out.pooler_output\n",
    "        cat_emb_list = [emb(cat_feats[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        cat_vec = torch.cat(cat_emb_list, dim=1)\n",
    "        all_feats = torch.cat([pooled, cat_vec, numeric_feats], dim=1)\n",
    "        return self.mlp(all_feats).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dd0636-f6ad-4cf1-a43a-e388a6689db6",
   "metadata": {},
   "source": [
    "Set all the parameters. criterion part is to balance the unbalanced dataset.\n",
    "Patience and below is because I want an early stopping so that the model would autometicly stop at the best place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eca13e2-ac23-4a1c-a042-893582628ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_categories = {c: df[c].nunique() for c in cat_cols}\n",
    "model = RedditModel(num_categories, cat_cols, numeric_cols, binary_cols).to(device)\n",
    "cnt = Counter(df[label_col])\n",
    "pos_weight_value = cnt[0] / cnt[1] \n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight_value]).to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "num_epochs = 20\n",
    "patience = 3\n",
    "best_val_loss = float('inf')\n",
    "trigger_times = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8526218f-994c-4359-b3df-bb55b61954bb",
   "metadata": {},
   "source": [
    "train the model and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4bb1b7-7bac-4cfe-9834-9c1048319d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss, correct, total = 0, 0, 0\n",
    "    for batch in train_loader:\n",
    "        input_ids_b = batch['input_ids'].to(device)\n",
    "        attention_mask_b = batch['attention_mask'].to(device)\n",
    "        cat_b = batch['cat_feats'].to(device)\n",
    "        numeric_b = batch['numeric_feats'].to(device)\n",
    "        labels_b = batch['label'].float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids_b, attention_mask_b, cat_b, numeric_b)\n",
    "        outputs = outputs.view(-1)\n",
    "        loss = criterion(outputs, labels_b)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * input_ids_b.size(0)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        correct += (preds == labels_b).sum().item()\n",
    "        total += labels_b.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_acc = correct / total\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids_b = batch['input_ids'].to(device)\n",
    "            attention_mask_b = batch['attention_mask'].to(device)\n",
    "            cat_b = batch['cat_feats'].to(device)\n",
    "            numeric_b = batch['numeric_feats'].to(device)\n",
    "            labels_b = batch['label'].float().to(device)\n",
    "\n",
    "            outputs = model(input_ids_b, attention_mask_b, cat_b, numeric_b)\n",
    "            outputs = outputs.view(-1)\n",
    "            loss = criterion(outputs, labels_b)\n",
    "\n",
    "            val_loss += loss.item() * input_ids_b.size(0)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "\n",
    "            val_correct += (preds == labels_b).sum().item()\n",
    "            val_total += labels_b.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels_b.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_acc = val_correct / val_total\n",
    "    val_f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        trigger_times = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            model.load_state_dict(torch.load('best_model.pt'))\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba720e2-a53a-475a-80dd-0f45f4a46169",
   "metadata": {},
   "source": [
    "count:\n",
    "thr=0.10 -> Acc=0.1119, F1=0.1911\n",
    "thr=0.15 -> Acc=0.1204, F1=0.1926\n",
    "thr=0.20 -> Acc=0.1354, F1=0.1947\n",
    "thr=0.25 -> Acc=0.1592, F1=0.1986\n",
    "thr=0.30 -> Acc=0.1943, F1=0.2031\n",
    "thr=0.35 -> Acc=0.2402, F1=0.2071\n",
    "thr=0.40 -> Acc=0.3110, F1=0.2136\n",
    "thr=0.45 -> Acc=0.4162, F1=0.2239\n",
    "thr=0.50 -> Acc=0.5683, F1=0.2327\n",
    "thr=0.55 -> Acc=0.7522, F1=0.2265\n",
    "thr=0.60 -> Acc=0.8307, F1=0.2023\n",
    "thr=0.65 -> Acc=0.8698, F1=0.1777\n",
    "thr=0.70 -> Acc=0.8881, F1=0.1523\n",
    "thr=0.75 -> Acc=0.8949, F1=0.1179\n",
    "thr=0.80 -> Acc=0.8976, F1=0.0997\n",
    "thr=0.85 -> Acc=0.8975, F1=0.0635\n",
    "thr=0.90 -> Acc=0.8955, F1=0.0171\n",
    "BEST: 0.5 0.232701867526535\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.92      0.56      0.70     11841\n",
    "           1       0.14      0.60      0.23      1390\n",
    "\n",
    "    accuracy                           0.57     13231\n",
    "   macro avg       0.53      0.58      0.46     13231\n",
    "weighted avg       0.84      0.57      0.65     13231\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c7fad1-89a1-4193-963b-c1d28546787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert:\n",
    "thr=0.10 -> Acc=0.1052, F1=0.1901\n",
    "thr=0.15 -> Acc=0.1055, F1=0.1900\n",
    "thr=0.20 -> Acc=0.1067, F1=0.1900\n",
    "thr=0.25 -> Acc=0.1125, F1=0.1902\n",
    "thr=0.30 -> Acc=0.1318, F1=0.1915\n",
    "thr=0.35 -> Acc=0.1843, F1=0.1941\n",
    "thr=0.40 -> Acc=0.2860, F1=0.1976\n",
    "thr=0.45 -> Acc=0.4358, F1=0.2046\n",
    "thr=0.50 -> Acc=0.6032, F1=0.2031\n",
    "thr=0.55 -> Acc=0.7400, F1=0.1948\n",
    "thr=0.60 -> Acc=0.8215, F1=0.1546\n",
    "thr=0.65 -> Acc=0.8655, F1=0.1214\n",
    "thr=0.70 -> Acc=0.8830, F1=0.0926\n",
    "thr=0.75 -> Acc=0.8902, F1=0.0668\n",
    "thr=0.80 -> Acc=0.8933, F1=0.0408\n",
    "thr=0.85 -> Acc=0.8937, F1=0.0112\n",
    "thr=0.90 -> Acc=0.8942, F1=0.0028\n",
    "Test Acc, F1: 0.6592850124707127 0.21161245190626093\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.69      0.78     11841\n",
    "           1       0.14      0.44      0.21      1390\n",
    "\n",
    "    accuracy                           0.66     13231\n",
    "   macro avg       0.53      0.56      0.50     13231\n",
    "weighted avg       0.83      0.66      0.72     13231\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaabc096-d340-4086-9ff7-c5c8fd9fb257",
   "metadata": {},
   "outputs": [],
   "source": [
    "none:\n",
    "thr=0.10 -> Acc=0.1050, F1=0.1900\n",
    "thr=0.15 -> Acc=0.1050, F1=0.1900\n",
    "thr=0.20 -> Acc=0.1050, F1=0.1900\n",
    "thr=0.25 -> Acc=0.1051, F1=0.1900\n",
    "thr=0.30 -> Acc=0.1050, F1=0.1899\n",
    "thr=0.35 -> Acc=0.1056, F1=0.1897\n",
    "thr=0.40 -> Acc=0.1150, F1=0.1901\n",
    "thr=0.45 -> Acc=0.2033, F1=0.1913\n",
    "thr=0.50 -> Acc=0.6098, F1=0.1790\n",
    "thr=0.55 -> Acc=0.8811, F1=0.0860\n",
    "thr=0.60 -> Acc=0.8853, F1=0.0789\n",
    "thr=0.65 -> Acc=0.8890, F1=0.0732\n",
    "thr=0.70 -> Acc=0.8911, F1=0.0600\n",
    "thr=0.75 -> Acc=0.8930, F1=0.0445\n",
    "thr=0.80 -> Acc=0.8931, F1=0.0262\n",
    "thr=0.85 -> Acc=0.8932, F1=0.0000\n",
    "thr=0.90 -> Acc=0.8950, F1=0.0000\n",
    "Test Acc, F1: 0.1969616809009145 0.1894881379205126\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.90      0.12      0.20     11841\n",
    "           1       0.11      0.89      0.19      1390\n",
    "\n",
    "    accuracy                           0.20     13231\n",
    "   macro avg       0.50      0.50      0.20     13231\n",
    "weighted avg       0.82      0.20      0.20     13231\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a151d3-cb88-40c7-a834-f3f31c5e2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert+MLP\n",
    "Epoch 1/20 | Train Loss: 1.4386, Train Acc: 0.5207 | Val Loss: 1.8189, Val Acc: 0.2324, Val F1: 0.1949\n",
    "Epoch 2/20 | Train Loss: 0.8904, Train Acc: 0.7681 | Val Loss: 2.0256, Val Acc: 0.5527, Val F1: 0.1970\n",
    "Epoch 3/20 | Train Loss: 0.5992, Train Acc: 0.8592 | Val Loss: 2.3622, Val Acc: 0.6228, Val F1: 0.2013\n",
    "Epoch 4/20 | Train Loss: 0.4676, Train Acc: 0.8934 | Val Loss: 2.4682, Val Acc: 0.7240, Val F1: 0.1913\n",
    "Early stopping triggered after 4 epochs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
